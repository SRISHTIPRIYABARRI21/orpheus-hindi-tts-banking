# Orpheus Hindi TTS - Production Banking/Finance Voice AI

> **Production-grade Hindi Text-to-Speech using Orpheus-3b-Hindi-FT-Q8_0 model**  
> Optimized for banking/finance voice AI applications with <300ms latency target

![Model](https://img.shields.io/badge/Model-Orpheus%203B%20Hindi-blue)
![Quantization](https://img.shields.io/badge/Quantization-Q8_0-green)
![Language](https://img.shields.io/badge/Language-Hindi-orange)
![Framework](https://img.shields.io/badge/Framework-FastAPI-red)
![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen)

## Overview

This repository provides a **complete, production-ready implementation** of the official [Orpheus-3b-Hindi-FT-Q8_0](https://huggingface.co/lex-au/Orpheus-3b-Hindi-FT-Q8_0.gguf) TTS model for Hindi language speech synthesis.

### Key Features

‚úÖ **Official Orpheus Hindi Model** - Uses the officially quantized Q8_0 variant  
‚úÖ **OpenAI-Compatible API** - Drop-in replacement for OpenAI's /v1/audio/speech endpoint  
‚úÖ **Real-time Streaming** - <300ms latency for banking/finance calls  
‚úÖ **Emotion Tags** - Support for laughter, sighs, and emotional expressions  
‚úÖ **Long-form Audio** - Intelligent batching with smooth crossfading for unlimited length  
‚úÖ **Banking Optimized** - Designed for EMI loan calls, customer service, financial IVR  
‚úÖ **Production Deployment** - Docker Compose with GPU acceleration and health checks  
‚úÖ **Concurrency Ready** - Handles 1000+ concurrent requests on H100/A100  

## Model Specifications

| Property | Value |
|----------|-------|
| **Model Name** | Orpheus-3b-Hindi-FT-Q8_0.gguf |
| **Parameters** | 3 Billion |
| **Quantization** | 8-bit (Q8_0 GGUF) |
| **Model Size** | 3.52 GB |
| **Audio Sample Rate** | 24 kHz |
| **Audio Format** | 16-bit Mono WAV |
| **Language** | Hindi |
| **Voice** | ‡§ã‡§§‡§ø‡§ï‡§æ (Ritika) - Female, expressive |
| **Supported Hardware** | NVIDIA RTX series, H100, A100, T4 |

### Available Voice

- **‡§ã‡§§‡§ø‡§ï‡§æ (Ritika)**: Female, expressive Hindi voice optimized for conversational naturalness in banking/finance scenarios

### Emotion Tags

```
<laugh>, <chuckle>   - Laughter sounds
<sigh>              - Sighing
<cough>, <sniffle>  - Subtle interruptions
<groan>, <yawn>, <gasp> - Emotional expressions
```

## Quick Start

### Prerequisites

- Docker and Docker Compose installed
- NVIDIA GPU with CUDA 12.4+ support
- NVIDIA Container Toolkit configured
- 8GB+ VRAM recommended (works on 6GB minimum)

### 1. Clone Repository

```bash
git clone https://github.com/SRISHTIPRIYABARRI21/orpheus-hindi-tts-banking.git
cd orpheus-hindi-tts-banking
```

### 2. Setup Environment

```bash
cp .env.example .env
# Edit .env if needed (defaults are optimized for most setups)
```

### 3. Start Services

```bash
# Download model + start both inference server and FastAPI
docker compose -f docker-compose-gpu.yml --profile init up model-init

# Then start the services
docker compose -f docker-compose-gpu.yml up -d
```

### 4. Verify Running

```bash
# Check health
curl http://localhost:5005/health

# Access API docs
open http://localhost:5005/docs
```

## API Usage

### OpenAI-Compatible Endpoint

```bash
curl -X POST http://localhost:5005/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "orpheus-hindi",
    "input": "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ø‡§π ‡§è‡§ï ‡§¨‡•à‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§ï‡•â‡§≤ ‡§π‡•à‡•§",
    "voice": "‡§ã‡§§‡§ø‡§ï‡§æ",
    "response_format": "wav",
    "speed": 1.0
  }' \
  --output speech.wav
```

### Python Example

```python
import asyncio
import aiohttp

async def generate_hindi_speech():
    url = "http://localhost:5005/v1/audio/speech"
    payload = {
        "input": "‡§Ü‡§™‡§ï‡§æ ‡§à‡§è‡§Æ‡§Ü‡§à ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•Å‡§Ü ‡§π‡•à‡•§",
        "model": "orpheus-hindi",
        "voice": "‡§ã‡§§‡§ø‡§ï‡§æ",
        "speed": 1.0
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(url, json=payload) as resp:
            audio = await resp.read()
            with open("output.wav", "wb") as f:
                f.write(audio)

# Run
asyncio.run(generate_hindi_speech())
```

### Real-time Streaming

```bash
curl -X POST http://localhost:5005/stream \
  -H "Content-Type: application/json" \
  -d '{
    "text": "‡§¨‡•à‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§∏‡•á‡§µ‡§æ ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ <laugh> ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§ñ‡§æ‡§§‡§æ ‡§®‡§Ç‡§¨‡§∞ ‡§¶‡•á‡§Ç‡•§",
    "voice": "‡§ã‡§§‡§ø‡§ï‡§æ"
  }' \
  --output streaming.wav
```

## Endpoints

| Method | Endpoint | Purpose |
|--------|----------|----------|
| GET | `/health` | Health check |
| GET | `/voices` | Available voices |
| POST | `/v1/audio/speech` | OpenAI-compatible TTS |
| POST | `/speak` | Legacy simple endpoint |
| POST | `/stream` | Real-time streaming |

## Environment Variables

```bash
# Inference Server
ORPHEUS_API_URL=http://llama-cpp-server:8000/v1/completions
ORPHEUS_API_TIMEOUT=120

# Model Parameters
ORPHEUS_MAX_TOKENS=8192
ORPHEUS_TEMPERATURE=0.6      # Lower = deterministic (ideal for banking)
ORPHEUS_TOP_P=0.9
ORPHEUS_SAMPLE_RATE=24000    # Orpheus standard

# Server
ORPHEUS_PORT=5005
ORPHEUS_HOST=0.0.0.0

# Model
ORPHEUS_MODEL_NAME=Orpheus-3b-Hindi-FT-Q8_0.gguf

# GPU
CUDA_VISIBLE_DEVICES=0
```

## Native Installation (Without Docker)

### 1. Python Setup

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt
```

### 2. Install PyTorch with CUDA

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

### 3. Start Inference Server

Download model first:
```bash
huggingface-cli download lex-au Orpheus-3b-Hindi-FT-Q8_0.gguf --local-dir ./models
```

Start llama.cpp server:
```bash
./llama-server -m models/Orpheus-3b-Hindi-FT-Q8_0.gguf \
  --ctx-size 8192 \
  --n-predict 8192 \
  --rope-scaling linear \
  --n-gpu-layers 99 \
  --port 5006
```

### 4. Start FastAPI Server

```bash
python app.py
```

Server runs on `http://localhost:5005`

## Performance Optimization

### Latency Targets

| Metric | Target | Notes |
|--------|--------|-------|
| First Token | <100ms | Critical for voice calls |
| End-to-End | <300ms | Per request |
| P99 Latency | <500ms | For 1000+ concurrent |

### GPU Memory Usage

| GPU | VRAM | Batch Size | Throughput |
|-----|------|------------|------------|
| RTX 4090 | 24GB | 32 | ~60 req/sec |
| RTX 4080 | 16GB | 16 | ~30 req/sec |
| A100 40GB | 40GB | 64 | ~120 req/sec |
| H100 80GB | 80GB | 128 | ~250 req/sec |

### Concurrency

Default configuration handles:
- **4 parallel workers** for token generation
- **Unlimited concurrent requests** at FastAPI level
- **Load balancing** via docker compose replicas

## Banking/Finance Use Cases

### EMI Loan Calls
```
Text: "‡§Ü‡§™‡§ï‡•á ‡§ñ‡§æ‡§§‡•á ‡§Æ‡•á‡§Ç ‚Çπ50,000 ‡§ï‡§æ ‡§à‡§è‡§Æ‡§Ü‡§à ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§¶‡•á‡§Ø ‡§π‡•à‡•§ <laugh> ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§Æ‡§Ø ‡§™‡§∞ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§"
```

### Customer Service
```
Text: "‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡§æ ‡§ñ‡§æ‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•à‡•§"
```

### Financial Alerts
```
Text: "‡§Ü‡§™‡§ï‡•á ‡§ñ‡§æ‡§§‡•á ‡§∏‡•á ‚Çπ10,000 ‡§ï‡•Ä ‡§∞‡§æ‡§∂‡§ø ‡§®‡§ø‡§ï‡§æ‡§≤‡•Ä ‡§ó‡§à ‡§π‡•à‡•§ <sigh>"
```

## Monitoring

### Health Check

```bash
curl http://localhost:5005/health
```

Response:
```json
{
  "status": "healthy",
  "model": "Orpheus-3b-Hindi-FT-Q8_0.gguf",
  "language": "Hindi",
  "voice": "‡§ã‡§§‡§ø‡§ï‡§æ (Ritika)"
}
```

### Metrics Endpoint

Access performance metrics via API:
```
GET /docs - Interactive API documentation
GET /metrics - Performance metrics (if enabled)
```

## Production Deployment

### Kubernetes Deployment

Example deployment manifest:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: orpheus-hindi-tts
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: orpheus-tts
        image: orpheus-hindi-tts:latest
        ports:
        - containerPort: 5005
        resources:
          requests:
            memory: "8Gi"
            nvidia.com/gpu: "1"
          limits:
            memory: "16Gi"
            nvidia.com/gpu: "1"
```

### Load Balancing

Using NGINX:

```nginx
upstream orpheus_backend {
    server localhost:5005;
    server localhost:5005;  # Multiple instances
}

server {
    listen 80;
    location / {
        proxy_pass http://orpheus_backend;
        proxy_buffering off;  # For streaming
    }
}
```

## Troubleshooting

### Connection Issues

```bash
# Check inference server is running
curl http://localhost:5006/health

# Check FastAPI is running
curl http://localhost:5005/health
```

### GPU Memory Issues

```bash
# Monitor GPU memory
nvidia-smi

# If OOM, reduce batch size in .env
ORPHEUS_MAX_TOKENS=4096
```

### Audio Quality

- **Increase temperature** (0.7-0.8) for more variation
- **Decrease temperature** (0.4-0.5) for consistency
- **Use emotion tags** for expressiveness

## Citation

If using this implementation in research:

```bibtex
@misc{orpheus-hindi-tts-banking-2025,
  title={Orpheus Hindi TTS - Production Banking/Finance Voice AI},
  author={Your Name},
  year={2025},
  publisher={GitHub},
  howpublished={\url{https://github.com/SRISHTIPRIYABARRI21/orpheus-hindi-tts-banking}}
}

@misc{orpheus-quantised-2025,
  author={Lex-au},
  title={Orpheus-3b-FT-Q8_0: Quantised TTS Model},
  year={2025},
  publisher={HuggingFace},
  howpublished={\url{https://huggingface.co/lex-au/Orpheus-3b-Hindi-FT-Q8_0.gguf}}
}

@misc{orpheus-tts-2025,
  author={Canopy Labs},
  title={Orpheus-3b Text-to-Speech Model},
  year={2025},
  publisher={HuggingFace},
  howpublished={\url{https://huggingface.co/canopylabs/orpheus-3b-0.1-ft}}
}
```

## License

Apache License 2.0 - See LICENSE file

## Support

- üìñ [Orpheus Official Documentation](https://github.com/canopyai/Orpheus-TTS)
- ü§ó [Model Card](https://huggingface.co/lex-au/Orpheus-3b-Hindi-FT-Q8_0.gguf)
- üêõ [Report Issues](https://github.com/SRISHTIPRIYABARRI21/orpheus-hindi-tts-banking/issues)

## Acknowledgments

- **Canopy Labs** for the original Orpheus TTS model
- **Lex-au** for the Hindi quantized model
- **NVIDIA** for CUDA and GPU infrastructure
- Banking/finance teams for optimization feedback
